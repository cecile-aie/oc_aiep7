{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c75a6a-5e11-4d2b-b2e8-015ebaa9ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc1bd8-5876-40cc-8417-b2a3e0fa8bd5",
   "metadata": {},
   "source": [
    "# Approche classique: embeddings de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c1fbba-9889-4ff0-8ba5-cf0746ed2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89af82ac-2e97-418a-9f95-318232d33bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train_df.csv\")\n",
    "train_df = train_df.iloc[:, 1:]\n",
    "test_df = pd.read_csv(\"./data/test_df.csv\")\n",
    "test_df = test_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8dd4844-90dd-490d-9fcc-6968a18166c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3397, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e477171-db32-4f25-a102-89d3658c59d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1457, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c5b939-69cd-4b18-bc3a-5167e8985f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"target\"]\n",
    "y_test = test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd2ac6-6cb7-419f-8a6b-043f1eb95ce3",
   "metadata": {},
   "source": [
    "### Embeddings de comptage des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0bad3-7d0e-448c-b702-419be74fdfc0",
   "metadata": {},
   "source": [
    "En réalisant les embeddings de façon indépendante sur le jeu de train et de test on s'assure qu'il n'y a pas de fuite de données et que l'appréciation de performance du modèle ne sera pas biaisée. Cependant il y a un fort risque d'avoir des OOV lors du test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730d1404-ab4f-4500-93ba-03204e8ec091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>preprocessed_tokenized</th>\n",
       "      <th>length_tokenized</th>\n",
       "      <th>length_preprocessed_tokenized</th>\n",
       "      <th>sia_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2177492915</td>\n",
       "      <td>Mon Jun 15 06:12:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ayyaya</td>\n",
       "      <td>@bradhfh well, I hope you don't even if you do...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;mention&gt; well, I hope you do not even if you ...</td>\n",
       "      <td>['&lt;mention&gt;', 'well', ',', 'I', 'hope', 'you',...</td>\n",
       "      <td>&lt;mention&gt; well  hope even think sleep airport ...</td>\n",
       "      <td>['&lt;', 'mention', '&gt;', 'well', 'hope', 'even', ...</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2046797519</td>\n",
       "      <td>Fri Jun 05 12:42:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ShyHustla</td>\n",
       "      <td>@MamaMisfit Yea but im still grounded for life...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;mention&gt; Yea but im still grounded for life a...</td>\n",
       "      <td>['&lt;mention&gt;', 'Yea', 'but', 'im', 'still', 'gr...</td>\n",
       "      <td>&lt;mention&gt; yea im still grounded life going mak...</td>\n",
       "      <td>['&lt;', 'mention', '&gt;', 'yea', 'im', 'still', 'g...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1558166592</td>\n",
       "      <td>Sun Apr 19 07:29:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>shirlise</td>\n",
       "      <td>Driving Alex to the airport  Then back to work...</td>\n",
       "      <td>0</td>\n",
       "      <td>Driving Alex to the airport Then back to work ...</td>\n",
       "      <td>['Driving', 'Alex', 'to', 'the', 'airport', 'T...</td>\n",
       "      <td>driving alex airport back work finish report  ...</td>\n",
       "      <td>['driving', 'alex', 'airport', 'back', 'work',...</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1827398448</td>\n",
       "      <td>Sun May 17 10:37:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ceibner</td>\n",
       "      <td>big fan of the Morrisey PJ's we got - was so t...</td>\n",
       "      <td>4</td>\n",
       "      <td>Big fan of the Morrisey PJ's we got - was so t...</td>\n",
       "      <td>['Big', 'fan', 'of', 'the', 'Morrisey', 'PJ', ...</td>\n",
       "      <td>big fan morrisey pj 's got - tempted stay &amp; sn...</td>\n",
       "      <td>['big', 'fan', 'morrisey', 'pj', \"'s\", 'got', ...</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1553668748</td>\n",
       "      <td>Sat Apr 18 14:53:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>firemanlv</td>\n",
       "      <td>PLEASE tell me they can put me on another earl...</td>\n",
       "      <td>0</td>\n",
       "      <td>PLEASE tell me they can put me on another earl...</td>\n",
       "      <td>['PLEASE', 'tell', 'me', 'they', 'can', 'put',...</td>\n",
       "      <td>please tell put another earlier flight since m...</td>\n",
       "      <td>['please', 'tell', 'put', 'another', 'earlier'...</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag       user  \\\n",
       "0       1  2177492915  Mon Jun 15 06:12:09 PDT 2009  NO_QUERY     Ayyaya   \n",
       "1       1  2046797519  Fri Jun 05 12:42:25 PDT 2009  NO_QUERY  ShyHustla   \n",
       "2       1  1558166592  Sun Apr 19 07:29:47 PDT 2009  NO_QUERY   shirlise   \n",
       "3       0  1827398448  Sun May 17 10:37:37 PDT 2009  NO_QUERY    ceibner   \n",
       "4       1  1553668748  Sat Apr 18 14:53:30 PDT 2009  NO_QUERY  firemanlv   \n",
       "\n",
       "                                                text  sentiment_score  \\\n",
       "0  @bradhfh well, I hope you don't even if you do...                0   \n",
       "1  @MamaMisfit Yea but im still grounded for life...                0   \n",
       "2  Driving Alex to the airport  Then back to work...                0   \n",
       "3  big fan of the Morrisey PJ's we got - was so t...                4   \n",
       "4  PLEASE tell me they can put me on another earl...                0   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  <mention> well, I hope you do not even if you ...   \n",
       "1  <mention> Yea but im still grounded for life a...   \n",
       "2  Driving Alex to the airport Then back to work ...   \n",
       "3  Big fan of the Morrisey PJ's we got - was so t...   \n",
       "4  PLEASE tell me they can put me on another earl...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  ['<mention>', 'well', ',', 'I', 'hope', 'you',...   \n",
       "1  ['<mention>', 'Yea', 'but', 'im', 'still', 'gr...   \n",
       "2  ['Driving', 'Alex', 'to', 'the', 'airport', 'T...   \n",
       "3  ['Big', 'fan', 'of', 'the', 'Morrisey', 'PJ', ...   \n",
       "4  ['PLEASE', 'tell', 'me', 'they', 'can', 'put',...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  <mention> well  hope even think sleep airport ...   \n",
       "1  <mention> yea im still grounded life going mak...   \n",
       "2  driving alex airport back work finish report  ...   \n",
       "3  big fan morrisey pj 's got - tempted stay & sn...   \n",
       "4  please tell put another earlier flight since m...   \n",
       "\n",
       "                              preprocessed_tokenized  length_tokenized  \\\n",
       "0  ['<', 'mention', '>', 'well', 'hope', 'even', ...                27   \n",
       "1  ['<', 'mention', '>', 'yea', 'im', 'still', 'g...                20   \n",
       "2  ['driving', 'alex', 'airport', 'back', 'work',...                31   \n",
       "3  ['big', 'fan', 'morrisey', 'pj', \"'s\", 'got', ...                33   \n",
       "4  ['please', 'tell', 'put', 'another', 'earlier'...                27   \n",
       "\n",
       "   length_preprocessed_tokenized  sia_sentiment  \n",
       "0                             14              0  \n",
       "1                             12              1  \n",
       "2                             16              0  \n",
       "3                             15              0  \n",
       "4                             14              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df .head()#[\"preprocessed_text\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b9034-a239-47d3-9ce7-0fa8be951c8d",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3011d67-0b40-41a5-80da-1e49274b8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "train_count_sparse = count_vectorizer.fit_transform(train_df['preprocessed_text'])\n",
    "\n",
    "test_count_sparse = count_vectorizer.transform(test_df['preprocessed_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a306f2-9e6c-4966-993c-adf234865d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Précaution à prendre avec les matrices creuses\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler(with_mean=False)\n",
    "# train_count_scaled = scaler.fit_transform(train_count_sparse)\n",
    "# test_count_scaled = scaler.fit_transform(test_count_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6647b1-1646-4fbe-b930-4a3a29620ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "# train_count = pd.DataFrame.sparse.from_spmatrix(train_count_sparse, columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# test_count = pd.DataFrame.sparse.from_spmatrix(test_count_sparse, columns=count_vectorizer.get_feature_names_out())\n",
    "train_count = pd.DataFrame(train_count_sparse.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "test_count = pd.DataFrame(test_count_sparse.toarray(), columns=count_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1940b3-84fb-41fd-b932-d6c930667b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "train_count[\"target\"] = y_train.values\n",
    "test_count[\"target\"] = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f14cca-23ae-435c-a2f4-f027972a4937",
   "metadata": {},
   "source": [
    "### Modélisation des embeddings : test rapides avec Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eceeaac-4ace-4e21-91be-d39e88d58c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# important pycaret supporte python 3.9 à 3.11\n",
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce43100-917e-4a61-8d8c-eefc32456346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pycaret\n",
    "# ! pip install pycaret[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ef0ced-c58d-4546-89f4-d6101f5ef67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307b553-cefc-4e91-bd32-9923492364d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pycaret classification and init setup\n",
    "from pycaret.classification import *\n",
    "s = setup(data=train_count, target='target', test_data=test_count, session_id = 123, index=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b8b34fb-7abf-4911-86d8-012b884eef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ClassificationExperiment and init the class\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6767fdfa-d974-4ad8-b9d3-bd845c12c8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pycaret.classification.oop.ClassificationExperiment"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of exp A CHANGER POUR MLFLOW à ce moment là le setup se fait avec \n",
    "type(exp)\n",
    "# exp.setup(data, target = 'Class variable', session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e36213cd-9445-4cbe-9b58-2a3149a0bf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e643a th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e643a_row0_col0, #T_e643a_row0_col1, #T_e643a_row0_col2, #T_e643a_row0_col4, #T_e643a_row0_col5, #T_e643a_row0_col6, #T_e643a_row0_col7, #T_e643a_row1_col0, #T_e643a_row1_col1, #T_e643a_row1_col2, #T_e643a_row1_col3, #T_e643a_row1_col4, #T_e643a_row1_col5, #T_e643a_row1_col6, #T_e643a_row1_col7, #T_e643a_row2_col0, #T_e643a_row2_col1, #T_e643a_row2_col2, #T_e643a_row2_col3, #T_e643a_row2_col4, #T_e643a_row2_col5, #T_e643a_row2_col6, #T_e643a_row2_col7, #T_e643a_row3_col0, #T_e643a_row3_col2, #T_e643a_row3_col3, #T_e643a_row3_col4, #T_e643a_row3_col7, #T_e643a_row4_col0, #T_e643a_row4_col1, #T_e643a_row4_col2, #T_e643a_row4_col3, #T_e643a_row4_col4, #T_e643a_row4_col5, #T_e643a_row4_col6, #T_e643a_row4_col7, #T_e643a_row5_col0, #T_e643a_row5_col1, #T_e643a_row5_col2, #T_e643a_row5_col3, #T_e643a_row5_col4, #T_e643a_row5_col5, #T_e643a_row5_col6, #T_e643a_row5_col7, #T_e643a_row6_col0, #T_e643a_row6_col1, #T_e643a_row6_col2, #T_e643a_row6_col3, #T_e643a_row6_col4, #T_e643a_row6_col5, #T_e643a_row6_col6, #T_e643a_row6_col7, #T_e643a_row7_col0, #T_e643a_row7_col1, #T_e643a_row7_col3, #T_e643a_row7_col4, #T_e643a_row7_col5, #T_e643a_row7_col6, #T_e643a_row8_col0, #T_e643a_row8_col1, #T_e643a_row8_col2, #T_e643a_row8_col3, #T_e643a_row8_col4, #T_e643a_row8_col5, #T_e643a_row8_col6, #T_e643a_row8_col7, #T_e643a_row9_col0, #T_e643a_row9_col1, #T_e643a_row9_col2, #T_e643a_row9_col3, #T_e643a_row9_col4, #T_e643a_row9_col5, #T_e643a_row9_col6, #T_e643a_row9_col7, #T_e643a_row10_col0, #T_e643a_row10_col1, #T_e643a_row10_col2, #T_e643a_row10_col3, #T_e643a_row10_col4, #T_e643a_row10_col5, #T_e643a_row10_col6, #T_e643a_row10_col7, #T_e643a_row11_col0, #T_e643a_row11_col1, #T_e643a_row11_col2, #T_e643a_row11_col3, #T_e643a_row11_col5, #T_e643a_row11_col6, #T_e643a_row11_col7, #T_e643a_row12_col0, #T_e643a_row12_col1, #T_e643a_row12_col2, #T_e643a_row12_col3, #T_e643a_row12_col4, #T_e643a_row12_col5, #T_e643a_row12_col6, #T_e643a_row12_col7, #T_e643a_row13_col0, #T_e643a_row13_col1, #T_e643a_row13_col2, #T_e643a_row13_col3, #T_e643a_row13_col4, #T_e643a_row13_col5, #T_e643a_row13_col6, #T_e643a_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e643a_row0_col3, #T_e643a_row3_col1, #T_e643a_row3_col5, #T_e643a_row3_col6, #T_e643a_row7_col2, #T_e643a_row7_col7, #T_e643a_row11_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_e643a_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_e643a_row1_col8, #T_e643a_row2_col8, #T_e643a_row3_col8, #T_e643a_row4_col8, #T_e643a_row5_col8, #T_e643a_row6_col8, #T_e643a_row7_col8, #T_e643a_row8_col8, #T_e643a_row9_col8, #T_e643a_row10_col8, #T_e643a_row11_col8, #T_e643a_row12_col8, #T_e643a_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e643a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e643a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e643a_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e643a_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_e643a_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_e643a_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_e643a_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_e643a_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_e643a_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_e643a_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row0\" class=\"row_heading level0 row0\" >dummy</th>\n",
       "      <td id=\"T_e643a_row0_col0\" class=\"data row0 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_e643a_row0_col1\" class=\"data row0 col1\" >0.5013</td>\n",
       "      <td id=\"T_e643a_row0_col2\" class=\"data row0 col2\" >0.5000</td>\n",
       "      <td id=\"T_e643a_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_e643a_row0_col4\" class=\"data row0 col4\" >0.5013</td>\n",
       "      <td id=\"T_e643a_row0_col5\" class=\"data row0 col5\" >0.6678</td>\n",
       "      <td id=\"T_e643a_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n",
       "      <td id=\"T_e643a_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n",
       "      <td id=\"T_e643a_row0_col8\" class=\"data row0 col8\" >0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row1\" class=\"row_heading level0 row1\" >nb</th>\n",
       "      <td id=\"T_e643a_row1_col0\" class=\"data row1 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_e643a_row1_col1\" class=\"data row1 col1\" >0.5558</td>\n",
       "      <td id=\"T_e643a_row1_col2\" class=\"data row1 col2\" >0.5542</td>\n",
       "      <td id=\"T_e643a_row1_col3\" class=\"data row1 col3\" >0.7992</td>\n",
       "      <td id=\"T_e643a_row1_col4\" class=\"data row1 col4\" >0.5389</td>\n",
       "      <td id=\"T_e643a_row1_col5\" class=\"data row1 col5\" >0.6435</td>\n",
       "      <td id=\"T_e643a_row1_col6\" class=\"data row1 col6\" >0.1105</td>\n",
       "      <td id=\"T_e643a_row1_col7\" class=\"data row1 col7\" >0.1256</td>\n",
       "      <td id=\"T_e643a_row1_col8\" class=\"data row1 col8\" >0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row2\" class=\"row_heading level0 row2\" >gbc</th>\n",
       "      <td id=\"T_e643a_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_e643a_row2_col1\" class=\"data row2 col1\" >0.6759</td>\n",
       "      <td id=\"T_e643a_row2_col2\" class=\"data row2 col2\" >0.7606</td>\n",
       "      <td id=\"T_e643a_row2_col3\" class=\"data row2 col3\" >0.7270</td>\n",
       "      <td id=\"T_e643a_row2_col4\" class=\"data row2 col4\" >0.6606</td>\n",
       "      <td id=\"T_e643a_row2_col5\" class=\"data row2 col5\" >0.6916</td>\n",
       "      <td id=\"T_e643a_row2_col6\" class=\"data row2 col6\" >0.3516</td>\n",
       "      <td id=\"T_e643a_row2_col7\" class=\"data row2 col7\" >0.3543</td>\n",
       "      <td id=\"T_e643a_row2_col8\" class=\"data row2 col8\" >12.5910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row3\" class=\"row_heading level0 row3\" >lr</th>\n",
       "      <td id=\"T_e643a_row3_col0\" class=\"data row3 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_e643a_row3_col1\" class=\"data row3 col1\" >0.7115</td>\n",
       "      <td id=\"T_e643a_row3_col2\" class=\"data row3 col2\" >0.7838</td>\n",
       "      <td id=\"T_e643a_row3_col3\" class=\"data row3 col3\" >0.6947</td>\n",
       "      <td id=\"T_e643a_row3_col4\" class=\"data row3 col4\" >0.7201</td>\n",
       "      <td id=\"T_e643a_row3_col5\" class=\"data row3 col5\" >0.7064</td>\n",
       "      <td id=\"T_e643a_row3_col6\" class=\"data row3 col6\" >0.4231</td>\n",
       "      <td id=\"T_e643a_row3_col7\" class=\"data row3 col7\" >0.4241</td>\n",
       "      <td id=\"T_e643a_row3_col8\" class=\"data row3 col8\" >1.1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row4\" class=\"row_heading level0 row4\" >svm</th>\n",
       "      <td id=\"T_e643a_row4_col0\" class=\"data row4 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_e643a_row4_col1\" class=\"data row4 col1\" >0.6821</td>\n",
       "      <td id=\"T_e643a_row4_col2\" class=\"data row4 col2\" >0.7521</td>\n",
       "      <td id=\"T_e643a_row4_col3\" class=\"data row4 col3\" >0.6818</td>\n",
       "      <td id=\"T_e643a_row4_col4\" class=\"data row4 col4\" >0.6864</td>\n",
       "      <td id=\"T_e643a_row4_col5\" class=\"data row4 col5\" >0.6823</td>\n",
       "      <td id=\"T_e643a_row4_col6\" class=\"data row4 col6\" >0.3642</td>\n",
       "      <td id=\"T_e643a_row4_col7\" class=\"data row4 col7\" >0.3660</td>\n",
       "      <td id=\"T_e643a_row4_col8\" class=\"data row4 col8\" >1.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "      <td id=\"T_e643a_row5_col0\" class=\"data row5 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_e643a_row5_col1\" class=\"data row5 col1\" >0.6906</td>\n",
       "      <td id=\"T_e643a_row5_col2\" class=\"data row5 col2\" >0.7565</td>\n",
       "      <td id=\"T_e643a_row5_col3\" class=\"data row5 col3\" >0.6782</td>\n",
       "      <td id=\"T_e643a_row5_col4\" class=\"data row5 col4\" >0.6975</td>\n",
       "      <td id=\"T_e643a_row5_col5\" class=\"data row5 col5\" >0.6869</td>\n",
       "      <td id=\"T_e643a_row5_col6\" class=\"data row5 col6\" >0.3813</td>\n",
       "      <td id=\"T_e643a_row5_col7\" class=\"data row5 col7\" >0.3823</td>\n",
       "      <td id=\"T_e643a_row5_col8\" class=\"data row5 col8\" >1.1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row6\" class=\"row_heading level0 row6\" >lightgbm</th>\n",
       "      <td id=\"T_e643a_row6_col0\" class=\"data row6 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_e643a_row6_col1\" class=\"data row6 col1\" >0.6862</td>\n",
       "      <td id=\"T_e643a_row6_col2\" class=\"data row6 col2\" >0.7670</td>\n",
       "      <td id=\"T_e643a_row6_col3\" class=\"data row6 col3\" >0.6671</td>\n",
       "      <td id=\"T_e643a_row6_col4\" class=\"data row6 col4\" >0.6951</td>\n",
       "      <td id=\"T_e643a_row6_col5\" class=\"data row6 col5\" >0.6798</td>\n",
       "      <td id=\"T_e643a_row6_col6\" class=\"data row6 col6\" >0.3725</td>\n",
       "      <td id=\"T_e643a_row6_col7\" class=\"data row6 col7\" >0.3737</td>\n",
       "      <td id=\"T_e643a_row6_col8\" class=\"data row6 col8\" >1.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row7\" class=\"row_heading level0 row7\" >et</th>\n",
       "      <td id=\"T_e643a_row7_col0\" class=\"data row7 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_e643a_row7_col1\" class=\"data row7 col1\" >0.7109</td>\n",
       "      <td id=\"T_e643a_row7_col2\" class=\"data row7 col2\" >0.7875</td>\n",
       "      <td id=\"T_e643a_row7_col3\" class=\"data row7 col3\" >0.6507</td>\n",
       "      <td id=\"T_e643a_row7_col4\" class=\"data row7 col4\" >0.7426</td>\n",
       "      <td id=\"T_e643a_row7_col5\" class=\"data row7 col5\" >0.6916</td>\n",
       "      <td id=\"T_e643a_row7_col6\" class=\"data row7 col6\" >0.4221</td>\n",
       "      <td id=\"T_e643a_row7_col7\" class=\"data row7 col7\" >0.4270</td>\n",
       "      <td id=\"T_e643a_row7_col8\" class=\"data row7 col8\" >2.0530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row8\" class=\"row_heading level0 row8\" >rf</th>\n",
       "      <td id=\"T_e643a_row8_col0\" class=\"data row8 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_e643a_row8_col1\" class=\"data row8 col1\" >0.6997</td>\n",
       "      <td id=\"T_e643a_row8_col2\" class=\"data row8 col2\" >0.7862</td>\n",
       "      <td id=\"T_e643a_row8_col3\" class=\"data row8 col3\" >0.6225</td>\n",
       "      <td id=\"T_e643a_row8_col4\" class=\"data row8 col4\" >0.7389</td>\n",
       "      <td id=\"T_e643a_row8_col5\" class=\"data row8 col5\" >0.6743</td>\n",
       "      <td id=\"T_e643a_row8_col6\" class=\"data row8 col6\" >0.3998</td>\n",
       "      <td id=\"T_e643a_row8_col7\" class=\"data row8 col7\" >0.4060</td>\n",
       "      <td id=\"T_e643a_row8_col8\" class=\"data row8 col8\" >1.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row9\" class=\"row_heading level0 row9\" >dt</th>\n",
       "      <td id=\"T_e643a_row9_col0\" class=\"data row9 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_e643a_row9_col1\" class=\"data row9 col1\" >0.6456</td>\n",
       "      <td id=\"T_e643a_row9_col2\" class=\"data row9 col2\" >0.6515</td>\n",
       "      <td id=\"T_e643a_row9_col3\" class=\"data row9 col3\" >0.6102</td>\n",
       "      <td id=\"T_e643a_row9_col4\" class=\"data row9 col4\" >0.6583</td>\n",
       "      <td id=\"T_e643a_row9_col5\" class=\"data row9 col5\" >0.6325</td>\n",
       "      <td id=\"T_e643a_row9_col6\" class=\"data row9 col6\" >0.2914</td>\n",
       "      <td id=\"T_e643a_row9_col7\" class=\"data row9 col7\" >0.2927</td>\n",
       "      <td id=\"T_e643a_row9_col8\" class=\"data row9 col8\" >1.7560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row10\" class=\"row_heading level0 row10\" >lda</th>\n",
       "      <td id=\"T_e643a_row10_col0\" class=\"data row10 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_e643a_row10_col1\" class=\"data row10 col1\" >0.5396</td>\n",
       "      <td id=\"T_e643a_row10_col2\" class=\"data row10 col2\" >0.5503</td>\n",
       "      <td id=\"T_e643a_row10_col3\" class=\"data row10 col3\" >0.5244</td>\n",
       "      <td id=\"T_e643a_row10_col4\" class=\"data row10 col4\" >0.5426</td>\n",
       "      <td id=\"T_e643a_row10_col5\" class=\"data row10 col5\" >0.5329</td>\n",
       "      <td id=\"T_e643a_row10_col6\" class=\"data row10 col6\" >0.0792</td>\n",
       "      <td id=\"T_e643a_row10_col7\" class=\"data row10 col7\" >0.0794</td>\n",
       "      <td id=\"T_e643a_row10_col8\" class=\"data row10 col8\" >13.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row11\" class=\"row_heading level0 row11\" >ada</th>\n",
       "      <td id=\"T_e643a_row11_col0\" class=\"data row11 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_e643a_row11_col1\" class=\"data row11 col1\" >0.6647</td>\n",
       "      <td id=\"T_e643a_row11_col2\" class=\"data row11 col2\" >0.7355</td>\n",
       "      <td id=\"T_e643a_row11_col3\" class=\"data row11 col3\" >0.5151</td>\n",
       "      <td id=\"T_e643a_row11_col4\" class=\"data row11 col4\" >0.7483</td>\n",
       "      <td id=\"T_e643a_row11_col5\" class=\"data row11 col5\" >0.6025</td>\n",
       "      <td id=\"T_e643a_row11_col6\" class=\"data row11 col6\" >0.3301</td>\n",
       "      <td id=\"T_e643a_row11_col7\" class=\"data row11 col7\" >0.3530</td>\n",
       "      <td id=\"T_e643a_row11_col8\" class=\"data row11 col8\" >6.8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n",
       "      <td id=\"T_e643a_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_e643a_row12_col1\" class=\"data row12 col1\" >0.5552</td>\n",
       "      <td id=\"T_e643a_row12_col2\" class=\"data row12 col2\" >0.5452</td>\n",
       "      <td id=\"T_e643a_row12_col3\" class=\"data row12 col3\" >0.4087</td>\n",
       "      <td id=\"T_e643a_row12_col4\" class=\"data row12 col4\" >0.5819</td>\n",
       "      <td id=\"T_e643a_row12_col5\" class=\"data row12 col5\" >0.4745</td>\n",
       "      <td id=\"T_e643a_row12_col6\" class=\"data row12 col6\" >0.1111</td>\n",
       "      <td id=\"T_e643a_row12_col7\" class=\"data row12 col7\" >0.1177</td>\n",
       "      <td id=\"T_e643a_row12_col8\" class=\"data row12 col8\" >6.7230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e643a_level0_row13\" class=\"row_heading level0 row13\" >knn</th>\n",
       "      <td id=\"T_e643a_row13_col0\" class=\"data row13 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_e643a_row13_col1\" class=\"data row13 col1\" >0.5949</td>\n",
       "      <td id=\"T_e643a_row13_col2\" class=\"data row13 col2\" >0.6570</td>\n",
       "      <td id=\"T_e643a_row13_col3\" class=\"data row13 col3\" >0.3959</td>\n",
       "      <td id=\"T_e643a_row13_col4\" class=\"data row13 col4\" >0.6668</td>\n",
       "      <td id=\"T_e643a_row13_col5\" class=\"data row13 col5\" >0.4894</td>\n",
       "      <td id=\"T_e643a_row13_col6\" class=\"data row13 col6\" >0.1910</td>\n",
       "      <td id=\"T_e643a_row13_col7\" class=\"data row13 col7\" >0.2115</td>\n",
       "      <td id=\"T_e643a_row13_col8\" class=\"data row13 col8\" >0.7860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b9500d2a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare baseline models and returns the best 6 ones\n",
    "best_models = compare_models(sort='Recall',n_select=6 ) #, include=[\"nb\", \"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d259cdb3-98d1-4794-83ce-95fd6b0d2daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sélection manuelle de modèles pour stacking\n",
    "nb = best_models[1]  # naives bayes \n",
    "lr = best_models[3]  # logistic regression \n",
    "gbc = best_models[2]  # Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb4ebabb-af9d-4ad9-8f33-778b357e786c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9d9e4_row10_col0, #T_9d9e4_row10_col1, #T_9d9e4_row10_col2, #T_9d9e4_row10_col3, #T_9d9e4_row10_col4, #T_9d9e4_row10_col5, #T_9d9e4_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9d9e4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9d9e4_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_9d9e4_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_9d9e4_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_9d9e4_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_9d9e4_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_9d9e4_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_9d9e4_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9d9e4_row0_col0\" class=\"data row0 col0\" >0.7353</td>\n",
       "      <td id=\"T_9d9e4_row0_col1\" class=\"data row0 col1\" >0.8213</td>\n",
       "      <td id=\"T_9d9e4_row0_col2\" class=\"data row0 col2\" >0.6901</td>\n",
       "      <td id=\"T_9d9e4_row0_col3\" class=\"data row0 col3\" >0.7613</td>\n",
       "      <td id=\"T_9d9e4_row0_col4\" class=\"data row0 col4\" >0.7239</td>\n",
       "      <td id=\"T_9d9e4_row0_col5\" class=\"data row0 col5\" >0.4709</td>\n",
       "      <td id=\"T_9d9e4_row0_col6\" class=\"data row0 col6\" >0.4730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9d9e4_row1_col0\" class=\"data row1 col0\" >0.6941</td>\n",
       "      <td id=\"T_9d9e4_row1_col1\" class=\"data row1 col1\" >0.7789</td>\n",
       "      <td id=\"T_9d9e4_row1_col2\" class=\"data row1 col2\" >0.6725</td>\n",
       "      <td id=\"T_9d9e4_row1_col3\" class=\"data row1 col3\" >0.7055</td>\n",
       "      <td id=\"T_9d9e4_row1_col4\" class=\"data row1 col4\" >0.6886</td>\n",
       "      <td id=\"T_9d9e4_row1_col5\" class=\"data row1 col5\" >0.3884</td>\n",
       "      <td id=\"T_9d9e4_row1_col6\" class=\"data row1 col6\" >0.3888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9d9e4_row2_col0\" class=\"data row2 col0\" >0.6706</td>\n",
       "      <td id=\"T_9d9e4_row2_col1\" class=\"data row2 col1\" >0.7696</td>\n",
       "      <td id=\"T_9d9e4_row2_col2\" class=\"data row2 col2\" >0.6199</td>\n",
       "      <td id=\"T_9d9e4_row2_col3\" class=\"data row2 col3\" >0.6928</td>\n",
       "      <td id=\"T_9d9e4_row2_col4\" class=\"data row2 col4\" >0.6543</td>\n",
       "      <td id=\"T_9d9e4_row2_col5\" class=\"data row2 col5\" >0.3416</td>\n",
       "      <td id=\"T_9d9e4_row2_col6\" class=\"data row2 col6\" >0.3435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9d9e4_row3_col0\" class=\"data row3 col0\" >0.7088</td>\n",
       "      <td id=\"T_9d9e4_row3_col1\" class=\"data row3 col1\" >0.8116</td>\n",
       "      <td id=\"T_9d9e4_row3_col2\" class=\"data row3 col2\" >0.6941</td>\n",
       "      <td id=\"T_9d9e4_row3_col3\" class=\"data row3 col3\" >0.7152</td>\n",
       "      <td id=\"T_9d9e4_row3_col4\" class=\"data row3 col4\" >0.7045</td>\n",
       "      <td id=\"T_9d9e4_row3_col5\" class=\"data row3 col5\" >0.4176</td>\n",
       "      <td id=\"T_9d9e4_row3_col6\" class=\"data row3 col6\" >0.4178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9d9e4_row4_col0\" class=\"data row4 col0\" >0.7176</td>\n",
       "      <td id=\"T_9d9e4_row4_col1\" class=\"data row4 col1\" >0.7886</td>\n",
       "      <td id=\"T_9d9e4_row4_col2\" class=\"data row4 col2\" >0.7353</td>\n",
       "      <td id=\"T_9d9e4_row4_col3\" class=\"data row4 col3\" >0.7102</td>\n",
       "      <td id=\"T_9d9e4_row4_col4\" class=\"data row4 col4\" >0.7225</td>\n",
       "      <td id=\"T_9d9e4_row4_col5\" class=\"data row4 col5\" >0.4353</td>\n",
       "      <td id=\"T_9d9e4_row4_col6\" class=\"data row4 col6\" >0.4356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9d9e4_row5_col0\" class=\"data row5 col0\" >0.7441</td>\n",
       "      <td id=\"T_9d9e4_row5_col1\" class=\"data row5 col1\" >0.8180</td>\n",
       "      <td id=\"T_9d9e4_row5_col2\" class=\"data row5 col2\" >0.7353</td>\n",
       "      <td id=\"T_9d9e4_row5_col3\" class=\"data row5 col3\" >0.7485</td>\n",
       "      <td id=\"T_9d9e4_row5_col4\" class=\"data row5 col4\" >0.7418</td>\n",
       "      <td id=\"T_9d9e4_row5_col5\" class=\"data row5 col5\" >0.4882</td>\n",
       "      <td id=\"T_9d9e4_row5_col6\" class=\"data row5 col6\" >0.4883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9d9e4_row6_col0\" class=\"data row6 col0\" >0.7176</td>\n",
       "      <td id=\"T_9d9e4_row6_col1\" class=\"data row6 col1\" >0.7958</td>\n",
       "      <td id=\"T_9d9e4_row6_col2\" class=\"data row6 col2\" >0.7412</td>\n",
       "      <td id=\"T_9d9e4_row6_col3\" class=\"data row6 col3\" >0.7079</td>\n",
       "      <td id=\"T_9d9e4_row6_col4\" class=\"data row6 col4\" >0.7241</td>\n",
       "      <td id=\"T_9d9e4_row6_col5\" class=\"data row6 col5\" >0.4353</td>\n",
       "      <td id=\"T_9d9e4_row6_col6\" class=\"data row6 col6\" >0.4358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9d9e4_row7_col0\" class=\"data row7 col0\" >0.6785</td>\n",
       "      <td id=\"T_9d9e4_row7_col1\" class=\"data row7 col1\" >0.7499</td>\n",
       "      <td id=\"T_9d9e4_row7_col2\" class=\"data row7 col2\" >0.6412</td>\n",
       "      <td id=\"T_9d9e4_row7_col3\" class=\"data row7 col3\" >0.6943</td>\n",
       "      <td id=\"T_9d9e4_row7_col4\" class=\"data row7 col4\" >0.6667</td>\n",
       "      <td id=\"T_9d9e4_row7_col5\" class=\"data row7 col5\" >0.3571</td>\n",
       "      <td id=\"T_9d9e4_row7_col6\" class=\"data row7 col6\" >0.3581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_9d9e4_row8_col0\" class=\"data row8 col0\" >0.7050</td>\n",
       "      <td id=\"T_9d9e4_row8_col1\" class=\"data row8 col1\" >0.7759</td>\n",
       "      <td id=\"T_9d9e4_row8_col2\" class=\"data row8 col2\" >0.7059</td>\n",
       "      <td id=\"T_9d9e4_row8_col3\" class=\"data row8 col3\" >0.7059</td>\n",
       "      <td id=\"T_9d9e4_row8_col4\" class=\"data row8 col4\" >0.7059</td>\n",
       "      <td id=\"T_9d9e4_row8_col5\" class=\"data row8 col5\" >0.4100</td>\n",
       "      <td id=\"T_9d9e4_row8_col6\" class=\"data row8 col6\" >0.4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_9d9e4_row9_col0\" class=\"data row9 col0\" >0.7404</td>\n",
       "      <td id=\"T_9d9e4_row9_col1\" class=\"data row9 col1\" >0.8017</td>\n",
       "      <td id=\"T_9d9e4_row9_col2\" class=\"data row9 col2\" >0.7647</td>\n",
       "      <td id=\"T_9d9e4_row9_col3\" class=\"data row9 col3\" >0.7303</td>\n",
       "      <td id=\"T_9d9e4_row9_col4\" class=\"data row9 col4\" >0.7471</td>\n",
       "      <td id=\"T_9d9e4_row9_col5\" class=\"data row9 col5\" >0.4807</td>\n",
       "      <td id=\"T_9d9e4_row9_col6\" class=\"data row9 col6\" >0.4813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_9d9e4_row10_col0\" class=\"data row10 col0\" >0.7112</td>\n",
       "      <td id=\"T_9d9e4_row10_col1\" class=\"data row10 col1\" >0.7911</td>\n",
       "      <td id=\"T_9d9e4_row10_col2\" class=\"data row10 col2\" >0.7000</td>\n",
       "      <td id=\"T_9d9e4_row10_col3\" class=\"data row10 col3\" >0.7172</td>\n",
       "      <td id=\"T_9d9e4_row10_col4\" class=\"data row10 col4\" >0.7080</td>\n",
       "      <td id=\"T_9d9e4_row10_col5\" class=\"data row10 col5\" >0.4225</td>\n",
       "      <td id=\"T_9d9e4_row10_col6\" class=\"data row10 col6\" >0.4232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d9e4_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_9d9e4_row11_col0\" class=\"data row11 col0\" >0.0238</td>\n",
       "      <td id=\"T_9d9e4_row11_col1\" class=\"data row11 col1\" >0.0218</td>\n",
       "      <td id=\"T_9d9e4_row11_col2\" class=\"data row11 col2\" >0.0438</td>\n",
       "      <td id=\"T_9d9e4_row11_col3\" class=\"data row11 col3\" >0.0215</td>\n",
       "      <td id=\"T_9d9e4_row11_col4\" class=\"data row11 col4\" >0.0290</td>\n",
       "      <td id=\"T_9d9e4_row11_col5\" class=\"data row11 col5\" >0.0475</td>\n",
       "      <td id=\"T_9d9e4_row11_col6\" class=\"data row11 col6\" >0.0473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b951afb5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construire le modèle Stacked avec ces modèles (on peut aussi créer des modèles lr = create_model(\"lr\"))\n",
    "stacked_model = stack_models([nb, lr, gbc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "effb55f7-95f9-4770-b656-c73e76a42796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;Naive Bayes&#x27;,\n",
       "                                GaussianNB(priors=None, var_smoothing=1e-09)),\n",
       "                               (&#x27;Logistic Regression&#x27;,\n",
       "                                LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                   dual=False,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   intercept_scaling=1,\n",
       "                                                   l1_ratio=None, max_iter=1000,\n",
       "                                                   multi_class=&#x27;auto&#x27;,\n",
       "                                                   n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                   random_state=123,\n",
       "                                                   solver=&#x27;lbfgs&#x27;, tol=0.0001,\n",
       "                                                   verbose=0,\n",
       "                                                   warm_start=Fals...\n",
       "                                                           validation_fraction=0.1,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=1000,\n",
       "                                                      multi_class=&#x27;auto&#x27;,\n",
       "                                                      n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                      random_state=123,\n",
       "                                                      solver=&#x27;lbfgs&#x27;,\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=1, passthrough=False, stack_method=&#x27;auto&#x27;, verbose=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;Naive Bayes&#x27;,\n",
       "                                GaussianNB(priors=None, var_smoothing=1e-09)),\n",
       "                               (&#x27;Logistic Regression&#x27;,\n",
       "                                LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                   dual=False,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   intercept_scaling=1,\n",
       "                                                   l1_ratio=None, max_iter=1000,\n",
       "                                                   multi_class=&#x27;auto&#x27;,\n",
       "                                                   n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                   random_state=123,\n",
       "                                                   solver=&#x27;lbfgs&#x27;, tol=0.0001,\n",
       "                                                   verbose=0,\n",
       "                                                   warm_start=Fals...\n",
       "                                                           validation_fraction=0.1,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=1000,\n",
       "                                                      multi_class=&#x27;auto&#x27;,\n",
       "                                                      n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                      random_state=123,\n",
       "                                                      solver=&#x27;lbfgs&#x27;,\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=1, passthrough=False, stack_method=&#x27;auto&#x27;, verbose=0)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>Naive Bayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>Logistic Regression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=123)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>Gradient Boosting Classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=123)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=123)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('Naive Bayes',\n",
       "                                GaussianNB(priors=None, var_smoothing=1e-09)),\n",
       "                               ('Logistic Regression',\n",
       "                                LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                   dual=False,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   intercept_scaling=1,\n",
       "                                                   l1_ratio=None, max_iter=1000,\n",
       "                                                   multi_class='auto',\n",
       "                                                   n_jobs=None, penalty='l2',\n",
       "                                                   random_state=123,\n",
       "                                                   solver='lbfgs', tol=0.0001,\n",
       "                                                   verbose=0,\n",
       "                                                   warm_start=Fals...\n",
       "                                                           validation_fraction=0.1,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=1000,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=123,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=1, passthrough=False, stack_method='auto', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d5281-d7cd-4f9c-af05-23722bb86ece",
   "metadata": {},
   "source": [
    "Le staking combine les forces des différents modèles en donnant des performances homogènes. Pour cet embedding nous allons utiliser le modèle composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5de0e8ff-0282-436d-8a22-2937bea1338d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Amélioration du meilleur modèle (logistic regression)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m tune_model(estimator\u001b[38;5;241m=\u001b[39mbest_models[\u001b[38;5;241m2\u001b[39m], \n\u001b[0;32m      3\u001b[0m                          optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m\"\u001b[39m, choose_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m                          verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\classification\\functional.py:1208\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1019\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1038\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CURRENT_EXPERIMENT\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1209\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1210\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1212\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1213\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1214\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1215\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1216\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1217\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1218\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1219\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1220\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1221\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1222\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1223\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1224\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1225\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1226\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1227\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1228\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\classification\\oop.py:1558\u001b[0m, in \u001b[0;36mClassificationExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1369\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1559\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1560\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1563\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1564\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1565\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1566\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1567\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1568\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1569\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1570\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1571\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1572\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1573\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1574\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1575\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1576\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1577\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1578\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:2718\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_base_sklearn_object()\n\u001b[0;32m   2715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   2716\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubProcess create_model() called ==================================\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2717\u001b[0m )\n\u001b[1;32m-> 2718\u001b[0m best_model, model_fit_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(\n\u001b[0;32m   2719\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   2720\u001b[0m     system\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2721\u001b[0m     display\u001b[38;5;241m=\u001b[39mdisplay,\n\u001b[0;32m   2722\u001b[0m     fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   2723\u001b[0m     \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   2724\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   2725\u001b[0m     fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   2726\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   2727\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params,\n\u001b[0;32m   2728\u001b[0m )\n\u001b[0;32m   2729\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpull()\n\u001b[0;32m   2730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   2731\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubProcess create_model() end ==================================\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2732\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1533\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, system, add_to_model_list, X_train_data, y_train_data, metrics, display, model_only, return_train_score, error_score, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model, model_fit_time\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m-> 1533\u001b[0m model, model_fit_time, model_results, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model_with_cv(\n\u001b[0;32m   1534\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1535\u001b[0m     data_X\u001b[38;5;241m=\u001b[39mdata_X,\n\u001b[0;32m   1536\u001b[0m     data_y\u001b[38;5;241m=\u001b[39mdata_y,\n\u001b[0;32m   1537\u001b[0m     fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1538\u001b[0m     \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1539\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m   1540\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1541\u001b[0m     metrics\u001b[38;5;241m=\u001b[39mmetrics,\n\u001b[0;32m   1542\u001b[0m     refit\u001b[38;5;241m=\u001b[39mrefit,\n\u001b[0;32m   1543\u001b[0m     system\u001b[38;5;241m=\u001b[39msystem,\n\u001b[0;32m   1544\u001b[0m     display\u001b[38;5;241m=\u001b[39mdisplay,\n\u001b[0;32m   1545\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m   1546\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1547\u001b[0m )\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# end runtime\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m runtime_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1223\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model_with_cv\u001b[1;34m(self, model, data_X, data_y, fit_kwargs, round, cv, groups, metrics, refit, system, display, error_score, return_train_score)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinalizing model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m redirect_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger):\n\u001b[1;32m-> 1223\u001b[0m     pipeline_with_model\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m   1224\u001b[0m     model_fit_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;66;03m# calculating metrics on predictions of complete train dataset\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\internal\\pipeline.py:278\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    277\u001b[0m     last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 278\u001b[0m     fitted_estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_fit(\n\u001b[0;32m    279\u001b[0m         clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]), X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Hacky way to make sure that the state of the estimator\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# loaded from cache is carried over to the estimator\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# in steps\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     _copy_estimator_state(fitted_estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\pycaret\\internal\\pipeline.py:69\u001b[0m, in \u001b[0;36m_fit_one\u001b[1;34m(transformer, X, y, message, params)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m signature(transformer\u001b[38;5;241m.\u001b[39mfit)\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[0;32m     68\u001b[0m             args\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[1;32m---> 69\u001b[0m         transformer\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformer\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[0;32m    785\u001b[0m     X_train,\n\u001b[0;32m    786\u001b[0m     y_train,\n\u001b[0;32m    787\u001b[0m     raw_predictions,\n\u001b[0;32m    788\u001b[0m     sample_weight_train,\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    790\u001b[0m     X_val,\n\u001b[0;32m    791\u001b[0m     y_val,\n\u001b[0;32m    792\u001b[0m     sample_weight_val,\n\u001b[0;32m    793\u001b[0m     begin_at_stage,\n\u001b[0;32m    794\u001b[0m     monitor,\n\u001b[0;32m    795\u001b[0m )\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    877\u001b[0m         )\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[0;32m    881\u001b[0m     i,\n\u001b[0;32m    882\u001b[0m     X,\n\u001b[0;32m    883\u001b[0m     y,\n\u001b[0;32m    884\u001b[0m     raw_predictions,\n\u001b[0;32m    885\u001b[0m     sample_weight,\n\u001b[0;32m    886\u001b[0m     sample_mask,\n\u001b[0;32m    887\u001b[0m     random_state,\n\u001b[0;32m    888\u001b[0m     X_csc\u001b[38;5;241m=\u001b[39mX_csc,\n\u001b[0;32m    889\u001b[0m     X_csr\u001b[38;5;241m=\u001b[39mX_csr,\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 490\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    491\u001b[0m     X, neg_g_view[:, k], sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1378\u001b[0m         X,\n\u001b[0;32m   1379\u001b[0m         y,\n\u001b[0;32m   1380\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1381\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1382\u001b[0m     )\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pycaret_env\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Amélioration du meilleur modèle (logistic regression)\n",
    "tuned_model = tune_model(estimator=best_models[2], \n",
    "                         optimize=\"Recall\", choose_better=True,\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490e2b3-8583-49cf-b257-bc5bfdc2a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model\n",
    "# ou plot_model(tuned_model, plot=\"parameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f0219-8e07-4387-b701-df3e63c25bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_model(tuned_model, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99137f3-7e0c-46c8-b78f-ee289f7ed1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_model, plot = 'auc') # Erreur sur les matrices creuses, même en normalisant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4149dc-5230-4f6c-a105-52fc700f0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_model, plot = 'class_report') # boundary: Erreur sur les matrices creuses, même en normalisant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e841f8-64ff-4adb-bc6e-562fb57ba5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdouts = predict_model(tuned_model)\n",
    "pred_holdouts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1d7c0-b502-468c-aef4-36a5751d78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdouts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4140239-5c3d-4a27-bf17-2a63bbb2e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the model (train on the entire dataset)\n",
    "finalize_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcaf85f-2e41-4ba5-9dcc-aa99fd4b31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(best, model_name='CountVectorizer_Best_Model')\n",
    "\n",
    "import os\n",
    "from datetime import date, datetime\n",
    "\n",
    "# os.chdir(\"C:/users/Cecil/Documents/oc_aiep7\")\n",
    "PATH = os.getcwd()+os.sep\n",
    "current_time = datetime.now().strftime(\"%m-%d-%Y_%H-%M\")\n",
    "save_model(tuned_model, PATH + \"models\" + os.sep + \"best_model_CountVectorizer_\" + current_time)\n",
    "\n",
    "\n",
    "# loaded_bestmodel = load_model('CountVectorizer_Best_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59398134-5798-4dbd-9052-ace3e6667a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer des prédictions pour le jeu d'entrainement\n",
    "predictions = predict_model(tuned_model, data=train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8917737-efe1-4f72-a26b-110e4ef8d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c3bcf-214c-455a-bd46-6a9e48abff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Séparer les features des labels\n",
    "features = df.drop(columns=['target', 'prediction_label', 'prediction_score'])\n",
    "true_labels = df['target']\n",
    "predicted_labels = df['prediction_label']\n",
    "\n",
    "# Appliquer Neighborhood Component Analysis (NCA) pour réduire à 2 dimensions\n",
    "nca = NeighborhoodComponentsAnalysis(n_components=2, random_state=42)\n",
    "nca_transformed = nca.fit_transform(features, true_labels)\n",
    "\n",
    "# Création d'un DataFrame pour la visualisation\n",
    "nca_df = pd.DataFrame(nca_transformed, columns=['NCA1', 'NCA2'])\n",
    "nca_df['True Labels'] = true_labels\n",
    "nca_df['Predicted Labels'] = predicted_labels\n",
    "\n",
    "# Identifier les points mal classés\n",
    "nca_df['Misclassified'] = nca_df['True Labels'] != nca_df['Predicted Labels']\n",
    "\n",
    "# Identifier les faux positifs et les faux négatifs\n",
    "nca_df['False Positive'] = (nca_df['True Labels'] == 0) & (nca_df['Predicted Labels'] == 1)\n",
    "nca_df['False Negative'] = (nca_df['True Labels'] == 1) & (nca_df['Predicted Labels'] == 0)\n",
    "\n",
    "# Retrouver les textes mal interprétés pour les faux positifs et les faux négatifs\n",
    "false_positive_texts = train_df.loc[nca_df[nca_df['False Positive']].index, 'text']\n",
    "false_negative_texts = train_df.loc[nca_df[nca_df['False Negative']].index, 'text']\n",
    "\n",
    "# Graphique 1 : Projection NCA avec les labels réels\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='NCA1', y='NCA2', hue='True Labels', data=nca_df, palette={0: 'green', 1: 'orange'}, s=100)\n",
    "plt.title('NCA Projection with True Labels')\n",
    "\n",
    "# Graphique 2 : Projection NCA avec les labels prédits et les points mal classés\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Points correctement classés (cercles)\n",
    "sns.scatterplot(x='NCA1', y='NCA2', hue='Predicted Labels', data=nca_df[~nca_df['Misclassified']], \n",
    "                palette={0: 'green', 1: 'orange'}, s=100, marker='o', label='Correctly Classified')\n",
    "\n",
    "# Points mal classés (croix \"x\")\n",
    "sns.scatterplot(x='NCA1', y='NCA2', hue='Predicted Labels', data=nca_df[nca_df['Misclassified']], \n",
    "                palette={0: 'red', 1: 'black'}, s=60, marker='x', edgecolor='red', linewidth=2, label='Misclassified')\n",
    "\n",
    "plt.title('NCA Projection with Predicted Labels and Misclassified Points')\n",
    "\n",
    "# Ajustement de la légende\n",
    "plt.legend(title='Classification à partir de CountVectorizer', loc='upper left')\n",
    "\n",
    "# Afficher les graphes\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les textes mal interprétés par groupe\n",
    "\n",
    "print(\"\\nFaux Positifs (Prédit comme 1, mais vrai label 0) :\")\n",
    "for text in false_positive_texts:\n",
    "    print(f\"- {text}\")\n",
    "    \n",
    "print(\"\\nFaux Négatifs (Prédit comme 0, mais vrai label 1) :\")\n",
    "for text in false_negative_texts:\n",
    "    print(f\"- {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec22eff-9b91-4bf7-9ad6-294dc539d569",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Supposons que vous ayez un DataFrame nommé 'df' contenant vos embeddings et les colonnes mentionnées\n",
    "# et un DataFrame 'train_df' contenant les textes dans la colonne 'text'.\n",
    "# df = pd.read_csv('path_to_your_data.csv')  # Chargez votre dataset si nécessaire\n",
    "# train_df = pd.read_csv('path_to_train_data.csv')  # Chargez votre dataset si nécessaire\n",
    "\n",
    "# Séparer les features des labels\n",
    "features = df.drop(columns=['target', 'prediction_label', 'prediction_score'])\n",
    "true_labels = df['target']\n",
    "predicted_labels = df['prediction_label']\n",
    "\n",
    "# Standardiser les données avant d'appliquer le Kernel PCA\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Appliquer Kernel PCA avec un noyau gaussien (RBF kernel) pour capturer les non-linéarités\n",
    "kpca = KernelPCA(n_components=2, kernel='rbf', gamma=0.001, random_state=42)\n",
    "kpca_transformed = kpca.fit_transform(features_scaled)\n",
    "\n",
    "# Création d'un DataFrame pour la visualisation\n",
    "kpca_df = pd.DataFrame(kpca_transformed, columns=['KPCA1', 'KPCA2'])\n",
    "kpca_df['True Labels'] = true_labels\n",
    "kpca_df['Predicted Labels'] = predicted_labels\n",
    "\n",
    "# Identifier les points mal classés\n",
    "kpca_df['Misclassified'] = kpca_df['True Labels'] != kpca_df['Predicted Labels']\n",
    "\n",
    "# Identifier les faux positifs et les faux négatifs\n",
    "kpca_df['False Positive'] = (kpca_df['True Labels'] == 0) & (kpca_df['Predicted Labels'] == 1)\n",
    "kpca_df['False Negative'] = (kpca_df['True Labels'] == 1) & (kpca_df['Predicted Labels'] == 0)\n",
    "\n",
    "# Retrouver les textes mal interprétés pour les faux positifs et les faux négatifs\n",
    "false_positive_texts = train_df.loc[kpca_df[kpca_df['False Positive']].index, 'text']\n",
    "false_negative_texts = train_df.loc[kpca_df[kpca_df['False Negative']].index, 'text']\n",
    "\n",
    "# Graphique 1 : Projection KPCA avec les labels réels\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='KPCA1', y='KPCA2', hue='True Labels', data=kpca_df, palette={0: 'blue', 1: 'red'}, s=100)\n",
    "plt.title('Kernel PCA Projection with True Labels')\n",
    "\n",
    "# Graphique 2 : Projection KPCA avec les labels prédits et les points mal classés\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Points correctement classés (cercles)\n",
    "sns.scatterplot(x='KPCA1', y='KPCA2', hue='Predicted Labels', data=kpca_df[~kpca_df['Misclassified']], \n",
    "                palette={0: 'green', 1: 'orange'}, s=100, marker='o')\n",
    "\n",
    "# Points mal classés (croix \"x\")\n",
    "sns.scatterplot(x='KPCA1', y='KPCA2', hue='Predicted Labels', data=kpca_df[kpca_df['Misclassified']], \n",
    "                palette={0: 'green', 1: 'orange'}, s=100, marker='x', edgecolor='red', linewidth=2)\n",
    "\n",
    "plt.title('Kernel PCA Projection with Predicted Labels and Misclassified Points')\n",
    "\n",
    "# Afficher les graphes\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les textes mal interprétés par groupe\n",
    "\n",
    "print(\"\\nFaux Négatifs (Prédit comme 0, mais vrai label 1) :\")\n",
    "for text in false_negative_texts:\n",
    "    print(f\"- {text}\")\n",
    "\n",
    "print(\"\\nFaux Positifs (Prédit comme 1, mais vrai label 0) :\")\n",
    "for text in false_positive_texts:\n",
    "    print(f\"- {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea271ce-4168-4a32-88e7-bc7b4fbf3dd0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Supposons que vous ayez un DataFrame nommé 'df' contenant vos embeddings et les colonnes mentionnées\n",
    "# et un DataFrame 'train_df' contenant les textes dans la colonne 'text'.\n",
    "# df = pd.read_csv('path_to_your_data.csv')  # Chargez votre dataset si nécessaire\n",
    "# train_df = pd.read_csv('path_to_train_data.csv')  # Chargez votre dataset si nécessaire\n",
    "\n",
    "# Séparer les features des labels\n",
    "features = df.drop(columns=['target', 'prediction_label', 'prediction_score'])\n",
    "true_labels = df['target']\n",
    "predicted_labels = df['prediction_label']\n",
    "\n",
    "# Standardiser les données avant d'appliquer le Kernel PCA\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Appliquer Kernel PCA avec un noyau gaussien (RBF kernel) pour réduire à 50 dimensions\n",
    "kpca = KernelPCA(n_components=50, kernel='rbf', gamma=0.001, random_state=42)\n",
    "kpca_transformed = kpca.fit_transform(features_scaled)\n",
    "\n",
    "# Appliquer t-SNE pour réduire les 50 dimensions de Kernel PCA à 2 dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=1000)\n",
    "tsne_transformed = tsne.fit_transform(kpca_transformed)\n",
    "\n",
    "# Création d'un DataFrame pour la visualisation\n",
    "tsne_df = pd.DataFrame(tsne_transformed, columns=['tSNE1', 'tSNE2'])\n",
    "tsne_df['True Labels'] = true_labels\n",
    "tsne_df['Predicted Labels'] = predicted_labels\n",
    "\n",
    "# Identifier les points mal classés\n",
    "tsne_df['Misclassified'] = tsne_df['True Labels'] != tsne_df['Predicted Labels']\n",
    "\n",
    "# Identifier les faux positifs et les faux négatifs\n",
    "tsne_df['False Positive'] = (tsne_df['True Labels'] == 0) & (tsne_df['Predicted Labels'] == 1)\n",
    "tsne_df['False Negative'] = (tsne_df['True Labels'] == 1) & (tsne_df['Predicted Labels'] == 0)\n",
    "\n",
    "# Retrouver les textes mal interprétés pour les faux positifs et les faux négatifs\n",
    "false_positive_texts = train_df.loc[tsne_df[tsne_df['False Positive']].index, 'text']\n",
    "false_negative_texts = train_df.loc[tsne_df[tsne_df['False Negative']].index, 'text']\n",
    "\n",
    "# Graphique 1 : Projection t-SNE avec les labels réels\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='tSNE1', y='tSNE2', hue='True Labels', data=tsne_df, palette={0: 'blue', 1: 'red'}, s=100)\n",
    "plt.title('t-SNE Projection with True Labels')\n",
    "\n",
    "# Graphique 2 : Projection t-SNE avec les labels prédits et les points mal classés\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Points correctement classés (cercles)\n",
    "sns.scatterplot(x='tSNE1', y='tSNE2', hue='Predicted Labels', data=tsne_df[~tsne_df['Misclassified']], \n",
    "                palette={0: 'green', 1: 'orange'}, s=100, marker='o')\n",
    "\n",
    "# Points mal classés (croix \"x\")\n",
    "sns.scatterplot(x='tSNE1', y='tSNE2', hue='Predicted Labels', data=tsne_df[tsne_df['Misclassified']], \n",
    "                palette={0: 'green', 1: 'orange'}, s=100, marker='x', edgecolor='red', linewidth=2)\n",
    "\n",
    "plt.title('t-SNE Projection with Predicted Labels and Misclassified Points')\n",
    "\n",
    "# Afficher les graphes\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les textes mal interprétés par groupe\n",
    "\n",
    "print(\"\\nFaux Négatifs (Prédit comme 0, mais vrai label 1) :\")\n",
    "for text in false_negative_texts:\n",
    "    print(f\"- {text}\")\n",
    "\n",
    "print(\"\\nFaux Positifs (Prédit comme 1, mais vrai label 0) :\")\n",
    "for text in false_positive_texts:\n",
    "    print(f\"- {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f746b8-2a99-4004-a124-33dcdbeb927c",
   "metadata": {},
   "source": [
    "#### TFIdF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5605c-92b1-43a1-8af3-e44abbcfb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 2,max_df = 0.5,ngram_range = (1,2))\n",
    "train_tfidf_sparse = tfidf.fit_transform(train_df['preprocessed_text'])\n",
    "test_tfidf_sparse = tfidf.transform(test_df['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d8634-c74d-4bc1-b636-6aa77bda5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "train_tfidf = pd.DataFrame(train_tfidf_sparse.toarray(), columns=tfidf.get_feature_names_out())\n",
    "test_tfidf = pd.DataFrame(test_tfidf_sparse.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6574b33-46b8-4186-90cc-7bd85ffbe02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "train_tfidf[\"target\"] = y_train.values\n",
    "test_tfidf[\"target\"] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927cd9ed-9869-4c83-9a4a-a5d04089840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pycaret classification and init setup\n",
    "from pycaret.classification import *\n",
    "s_tf = setup(data=train_tfidf, target='target', test_data=test_tfidf, session_id = 123, index=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13070017-0b27-4c0b-975f-00c0bf468d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare baseline models and returns the best 6 ones\n",
    "best_models_tf = compare_models(sort='Precision', n_select=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86237c5-bbe5-4faf-9c29-6c85fe0d5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amélioration du meilleur modèle (logistic regression)\n",
    "tuned_model_tf = tune_model(estimator=best_models_tf[0], \n",
    "                         optimize=\"Precision\", choose_better=True,\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c414b236-7700-4d80-9076-031c248a03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82e58d-19b8-42e5-be72-59d0c5709024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_model(tuned_model_tf, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b884b71-cd09-4e46-9cf5-e1f3a90146d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_model_tf, plot = 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f698e5-ec3a-42d0-a058-fcdec93b966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdouts_tf = predict_model(tuned_model_tf)\n",
    "pred_holdouts_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274cfa4-7f74-4ee1-9d36-a8732fd5faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the model (train on the entire dataset)\n",
    "finalize_model(tuned_model_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7658e-2b47-4687-8fa0-8a1e337a2304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_model(best, model_name='CountVectorizer_Best_Model')\n",
    "\n",
    "import os\n",
    "from datetime import date, datetime\n",
    "\n",
    "# os.chdir(\"C:/users/Cecil/Documents/oc_aiep7\")\n",
    "PATH = os.getcwd()+os.sep\n",
    "current_time = datetime.now().strftime(\"%m-%d-%Y_%H-%M\")\n",
    "save_model(tuned_model_tf, PATH + \"models\" + os.sep + \"best_model_TFIdF_\" + current_time)\n",
    "\n",
    "\n",
    "# loaded_bestmodel = load_model('CountVectorizer_Best_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d2231-920a-409f-b80a-ea8b9260fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer des prédictions pour le jeu d'entrainement\n",
    "predictions_tf = predict_model(tuned_model_tf, data=train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83024f-6ee8-4f98-af99-e43d6e91eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictions_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415c220-99ce-44a4-a25c-d18daf3b25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Supposons que vous ayez un DataFrame nommé 'df' contenant vos embeddings et les colonnes mentionnées\n",
    "# et un DataFrame 'train_df' contenant les textes dans la colonne 'text'.\n",
    "# df = pd.read_csv('path_to_your_data.csv')  # Chargez votre dataset si nécessaire\n",
    "# train_df = pd.read_csv('path_to_train_data.csv')  # Chargez votre dataset si nécessaire\n",
    "\n",
    "# Séparer les features des labels\n",
    "features = df.drop(columns=['target', 'prediction_label', 'prediction_score'])\n",
    "true_labels = df['target']\n",
    "predicted_labels = df['prediction_label']\n",
    "\n",
    "# Appliquer Neighborhood Component Analysis (NCA) pour réduire à 2 dimensions\n",
    "nca = NeighborhoodComponentsAnalysis(n_components=2, random_state=42)\n",
    "nca_transformed = nca.fit_transform(features, true_labels)\n",
    "\n",
    "# Création d'un DataFrame pour la visualisation\n",
    "nca_df = pd.DataFrame(nca_transformed, columns=['NCA1', 'NCA2'])\n",
    "nca_df['True Labels'] = true_labels\n",
    "nca_df['Predicted Labels'] = predicted_labels\n",
    "\n",
    "# Identifier les points mal classés\n",
    "nca_df['Misclassified'] = nca_df['True Labels'] != nca_df['Predicted Labels']\n",
    "\n",
    "# Identifier les faux positifs et les faux négatifs\n",
    "nca_df['False Positive'] = (nca_df['True Labels'] == 0) & (nca_df['Predicted Labels'] == 1)\n",
    "nca_df['False Negative'] = (nca_df['True Labels'] == 1) & (nca_df['Predicted Labels'] == 0)\n",
    "\n",
    "# Retrouver les textes mal interprétés pour les faux positifs et les faux négatifs\n",
    "false_positive_texts = train_df.loc[nca_df[nca_df['False Positive']].index, 'text']\n",
    "false_negative_texts = train_df.loc[nca_df[nca_df['False Negative']].index, 'text']\n",
    "\n",
    "# Graphique 1 : Projection NCA avec les labels réels\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='NCA1', y='NCA2', hue='True Labels', data=nca_df, palette={0: 'green', 1: 'orange'}, s=100)\n",
    "plt.title('NCA Projection with True Labels')\n",
    "\n",
    "# Graphique 2 : Projection NCA avec les labels prédits et les points mal classés\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Points correctement classés (cercles)\n",
    "sns.scatterplot(x='NCA1', y='NCA2', hue='Predicted Labels', data=nca_df[~nca_df['Misclassified']], \n",
    "                palette={0: 'green', 1: 'orange'}, s=100, marker='o', label='Correctly Classified')\n",
    "\n",
    "# Points mal classés (croix \"x\")\n",
    "sns.scatterplot(x='NCA1', y='NCA2', hue='Predicted Labels', data=nca_df[nca_df['Misclassified']], \n",
    "                palette={0: 'red', 1: 'black'}, s=60, marker='x', edgecolor='red', linewidth=2, label='Misclassified')\n",
    "\n",
    "plt.title('NCA Projection with Predicted Labels and Misclassified Points')\n",
    "\n",
    "# Ajustement de la légende\n",
    "plt.legend(title='Classification', loc='upper left')\n",
    "\n",
    "# Afficher les graphes\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les textes mal interprétés par groupe\n",
    "\n",
    "print(\"\\nFaux Positifs (Prédit comme 1, mais vrai label 0) :\")\n",
    "for text in false_positive_texts:\n",
    "    print(f\"- {text}\")\n",
    "    \n",
    "print(\"\\nFaux Négatifs (Prédit comme 0, mais vrai label 1) :\")\n",
    "for text in false_negative_texts:\n",
    "    print(f\"- {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13872983-5ffe-42e8-a4b6-192d9b09ed01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "pycaret_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
