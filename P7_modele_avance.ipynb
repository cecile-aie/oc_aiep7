{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c48b4e0-4ec8-439c-b899-590b8e9a1612",
   "metadata": {
    "id": "8c48b4e0-4ec8-439c-b899-590b8e9a1612"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nUqPSWrcNAua",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21120,
     "status": "ok",
     "timestamp": 1727940032741,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "nUqPSWrcNAua",
    "outputId": "6a3a53e8-f06e-4837-fb57-3d561f513099"
   },
   "outputs": [],
   "source": [
    "# # utilisation dans Google collab\n",
    "# print('Mounting your Google Drive...')\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# print('Opening the file...')\n",
    "# %cd /content/drive/My Drive/P7\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c853195-086e-48ae-866a-c24786cf3062",
   "metadata": {
    "executionInfo": {
     "elapsed": 4653,
     "status": "ok",
     "timestamp": 1727940043161,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "5c853195-086e-48ae-866a-c24786cf3062"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0eff01d-49ef-4b5f-af09-89131d03ab4e",
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1727939493961,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "c0eff01d-49ef-4b5f-af09-89131d03ab4e"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "# Paramètres du modèle Word2Vec\n",
    "w2v_size = 300        # Taille des vecteurs\n",
    "w2v_window = 5        # Taille de la fenêtre contextuelle\n",
    "w2v_min_count = 1     # Nombre minimum d'occurrences d'un mot pour être pris en compte\n",
    "w2v_epochs = 100      # Nombre d'itérations (époques)\n",
    "workers = multiprocessing.cpu_count()  # Utilisation de tous les cœurs disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1d172-1fbf-4948-9be9-1a7dc3a329aa",
   "metadata": {
    "id": "abc1d172-1fbf-4948-9be9-1a7dc3a329aa"
   },
   "source": [
    "### Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282efece-f6ea-4be2-aa89-8a64a37ceef6",
   "metadata": {
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1727940116308,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "282efece-f6ea-4be2-aa89-8a64a37ceef6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"./data/train_df.csv\")\n",
    "train_df = train_df.iloc[:, 1:]\n",
    "test_df = pd.read_csv(\"./data/test_df.csv\")\n",
    "test_df = test_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631e1c2-e820-4133-9c1b-7af79604483b",
   "metadata": {
    "id": "d631e1c2-e820-4133-9c1b-7af79604483b"
   },
   "source": [
    "### Préparation des sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8cafb4-07b4-4f43-9e89-591d0f766bab",
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1727939537153,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "1e8cafb4-07b4-4f43-9e89-591d0f766bab"
   },
   "outputs": [],
   "source": [
    "# Préparation des sentences à partir de la colonne 'preprocessed_text'\n",
    "# Tokenisation de chaque phrase en séparant les mots sur les espaces\n",
    "train_sentences = [sentence.split() for sentence in train_df['preprocessed_text'].astype(str)]\n",
    "test_sentences = [sentence.split() for sentence in test_df['preprocessed_text'].astype(str)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408ba1b-b6a7-4efe-a6d3-1fbf87acbfbc",
   "metadata": {
    "id": "9408ba1b-b6a7-4efe-a6d3-1fbf87acbfbc"
   },
   "source": [
    "### Modèle Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec894154-5340-4778-b302-2a674bcc4d77",
   "metadata": {
    "executionInfo": {
     "elapsed": 1502,
     "status": "ok",
     "timestamp": 1727939544455,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "ec894154-5340-4778-b302-2a674bcc4d77"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# Instanciation du modèle Word2Vec\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=train_sentences,   # Les phrases tokenisées d'entraînement\n",
    "    vector_size=w2v_size,        # Taille des vecteurs\n",
    "    window=w2v_window,           # Taille de la fenêtre contextuelle\n",
    "    min_count=w2v_min_count,     # Seuil d'apparition minimum d'un mot\n",
    "    workers=workers,             # Nombre de threads (CPU cores) à utiliser\n",
    "    sg=1                         # Utilisation de Skip-gram (si sg=0, on utilise CBOW)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f37f133-9377-45fc-8dc8-7f2632c24b5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29157,
     "status": "ok",
     "timestamp": 1727939578276,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "6f37f133-9377-45fc-8dc8-7f2632c24b5a",
    "outputId": "f5324401-2b9b-4af2-daef-5766c36ae340"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935595, 3588100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "w2v_model.train(train_sentences, total_examples=len(train_sentences), epochs=w2v_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5f7d4f-4cc1-470f-9a3d-51d1e2ee6a7d",
   "metadata": {
    "id": "7f5f7d4f-4cc1-470f-9a3d-51d1e2ee6a7d"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle après entraînement\n",
    "w2v_model.save(\"./models/word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae58daf-7741-4ff7-b8ad-40f224f3ed45",
   "metadata": {
    "id": "3ae58daf-7741-4ff7-b8ad-40f224f3ed45"
   },
   "source": [
    "### Matrice d'embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd8accf-bb42-46d0-a9c1-b3aca942e1a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1727939636265,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "ebd8accf-bb42-46d0-a9c1-b3aca942e1a0",
    "outputId": "89172935-e372-4f6d-9cb6-c253d64290f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice d'embedding de taille : (6691, 300)\n"
     ]
    }
   ],
   "source": [
    "# Taille du vocabulaire (le nombre de mots uniques)\n",
    "vocab_size = len(w2v_model.wv.index_to_key)\n",
    "\n",
    "# Extraction de la matrice d'embedding\n",
    "embedding_matrix = []\n",
    "for word in w2v_model.wv.index_to_key:\n",
    "    embedding_matrix.append(w2v_model.wv[word])\n",
    "\n",
    "# Conversion en numpy array\n",
    "import numpy as np\n",
    "embedding_matrix = np.array(embedding_matrix)\n",
    "\n",
    "# Dimensions de la matrice d'embedding : vocab_size x w2v_size\n",
    "print(\"Matrice d'embedding de taille :\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54977f-1009-417c-aab3-c79ecdb857e3",
   "metadata": {
    "id": "bb54977f-1009-417c-aab3-c79ecdb857e3"
   },
   "source": [
    "### Modèle d'embedding Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b81d3c-da72-4589-88ae-c12a61ebbf1b",
   "metadata": {
    "id": "b8b81d3c-da72-4589-88ae-c12a61ebbf1b"
   },
   "source": [
    "Les essais avec un modèle simple (LSTM et dense) ont montré un sur-apprentissage important. Il faut l'optimiser avec dropout, regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5273ef87-c19e-4ec6-a56c-d77f2205c38b",
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1727939644405,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "5273ef87-c19e-4ec6-a56c-d77f2205c38b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Paramètres\n",
    "maxlen = 31  # Longueur maximale des séquences de mots\n",
    "vocab_size = len(w2v_model.wv.index_to_key)  # Taille du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9f9757-8652-4db4-b7fa-46712a86456a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1727939647618,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "4d9f9757-8652-4db4-b7fa-46712a86456a",
    "outputId": "a8758927-7c03-4afa-ae91-fe217028f7e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │       \u001b[38;5;34m2,007,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciation du modèle séquentiel 1\n",
    "model = Sequential()\n",
    "\n",
    "# Ajout de la couche d'embedding avec la matrice pré-entraînée\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size,       # Taille du vocabulaire\n",
    "    output_dim=w2v_size,        # Dimension des vecteurs d'embedding\n",
    "    weights=[embedding_matrix], # Utilisation de la matrice d'embedding pré-entraînée\n",
    "    trainable=False             # Geler les poids de l'embedding\n",
    "))\n",
    "\n",
    "# Ajout d'une couche LSTM pour capturer les relations séquentielles\n",
    "model.add(LSTM(128))\n",
    "\n",
    "# Ajout d'une couche de sortie (par exemple, pour de la classification binaire)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5735821c-b461-4b42-b7db-f2859444d7bd",
   "metadata": {
    "id": "5735821c-b461-4b42-b7db-f2859444d7bd",
    "outputId": "677c86f8-2b96-4a3a-b9e2-64d1d062966c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m2,007,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciation du modèle séquentiel 2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Ajout de la régularisation L2 dans la couche LSTM et la couche Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=w2v_size, weights=[embedding_matrix],\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128, kernel_regularizer=l2(0.01)))  # Ajout de la régularisation L2\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))  # Ajout L2 dans la couche Dense\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f976e24-a707-44cc-8940-b5370811e2da",
   "metadata": {
    "id": "7f976e24-a707-44cc-8940-b5370811e2da",
    "outputId": "8c52f96d-2264-4ba6-ebe1-98af7bb8ea3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m2,007,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modèle 3 avec dropout\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Ajout de Dropout après la couche LSTM pour prévenir l'overfitting\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=w2v_size, weights=[embedding_matrix],\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))  # Dropout de 50% des neurones\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15f5725-a560-4113-8f96-9537fffd2f26",
   "metadata": {
    "id": "d15f5725-a560-4113-8f96-9537fffd2f26",
    "outputId": "63378807-0878-41ad-c409-f0de0ceb09f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\AIEP7\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# diminuer la complexité LSTM ou utiliser GRU\n",
    "# Réduction du nombre d'unités dans la couche LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=w2v_size, weights=[embedding_matrix],\n",
    "                    input_length=maxlen, trainable=False))\n",
    "model.add(LSTM(64))  # Moins d'unités LSTM\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f450ee3-46b3-4761-819f-c0cb866c00db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1727939669669,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "4f450ee3-46b3-4761-819f-c0cb866c00db",
    "outputId": "23fff064-7735-4f15-9759-7d2d19e62515"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m2,007,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,300</span> (7.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,007,300\u001b[0m (7.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code du modèle avec GRU, Dropout et régularisation L2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam  # Importer Adam pour ajuster le learning rate\n",
    "\n",
    "# Paramètres de régularisation et Dropout\n",
    "dropout_rate = 0.5      # Pourcentage de neurones ignorés\n",
    "l2_lambda = 0.01        # Facteur de régularisation L2\n",
    "learning_rate = 0.0001  # Taux d'apprentissage spécifique\n",
    "\n",
    "# Instanciation du modèle séquentiel\n",
    "model = Sequential()\n",
    "\n",
    "# 1. Couche d'embedding avec la matrice Word2Vec pré-entraînée\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size,       # Taille du vocabulaire\n",
    "    output_dim=w2v_size,        # Dimension des vecteurs d'embedding\n",
    "    weights=[embedding_matrix], # Matrice d'embedding pré-entraînée\n",
    "    input_length=maxlen,        # Longueur maximale des séquences\n",
    "    trainable=False             # Geler les poids de l'embedding\n",
    "))\n",
    "\n",
    "# 2. Couche GRU avec Dropout et régularisation L2\n",
    "model.add(GRU(\n",
    "    units=128,                    # Nombre d'unités GRU\n",
    "    kernel_regularizer=l2(l2_lambda),  # Régularisation L2 sur les poids\n",
    "    recurrent_regularizer=l2(l2_lambda),  # Régularisation L2 sur les poids récurrents\n",
    "    dropout=dropout_rate,         # Dropout sur les connexions entrantes\n",
    "    recurrent_dropout=dropout_rate  # Dropout sur les connexions récurrentes\n",
    "))\n",
    "\n",
    "# 3. Couche de sortie Dense avec régularisation L2\n",
    "model.add(Dense(\n",
    "    units=1,                      # Pour une tâche de classification binaire\n",
    "    activation='sigmoid',          # Sigmoid pour la probabilité binaire\n",
    "    kernel_regularizer=l2(l2_lambda)  # Régularisation L2 sur la couche de sortie\n",
    "))\n",
    "\n",
    "# Définir l'optimiseur Adam avec un learning rate spécifique\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(\n",
    "    optimizer=optimizer,          # Utiliser l'optimiseur Adam avec le learning rate défini\n",
    "    loss='binary_crossentropy',   # Fonction de perte pour une classification binaire\n",
    "    metrics=['accuracy']          # Métrique d'accuracy\n",
    ")\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f60a5-5114-4ba9-8ae0-b23d2d7fac96",
   "metadata": {
    "id": "715f60a5-5114-4ba9-8ae0-b23d2d7fac96"
   },
   "source": [
    "### Préparation des données pour l'exécution du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fde9ff8d-c867-468c-8ebf-252343e6d087",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1727939675441,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "fde9ff8d-c867-468c-8ebf-252343e6d087",
    "outputId": "bfc2b986-48a8-454a-8fa3-9e2de63dae57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   47   31   96   88  101    3 1539 2300 2874  442    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   1  589   82   32   49  161   12   84  353 2299    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [ 332 2298    3   11   68  565  888   78  562  319 2876    0  323   57\n",
      "  2879    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [ 236  425 2880 2881    6   18   17  977  195   21 2882 2848  545   51\n",
      "     2    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [ 185  355  317  138  546    2  327  330  706    0  218  705  370   14\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Création d'un dictionnaire mot->index à partir du vocabulaire de Word2Vec\n",
    "word_index = {word: i for i, word in enumerate(w2v_model.wv.index_to_key)}\n",
    "\n",
    "# Fonction pour convertir les phrases en séquences d'index\n",
    "def sentences_to_sequences(sentences, word_index):\n",
    "    sequences = []\n",
    "    for sentence in sentences:\n",
    "        seq = [word_index.get(word, 0) for word in sentence]  # Remplacer les mots inconnus par 0\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "# Conversion des phrases d'entraînement et de test en séquences d'index\n",
    "train_sequences = sentences_to_sequences(train_sentences, word_index)\n",
    "test_sequences = sentences_to_sequences(test_sentences, word_index)\n",
    "\n",
    "# Padding des séquences pour qu'elles aient toutes la même longueur (maxlen)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=maxlen, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=maxlen, padding='post')\n",
    "\n",
    "# Exemple d'affichage des séquences après padding\n",
    "print(train_padded[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b466d-2398-4cfb-9db4-233f228d1869",
   "metadata": {
    "id": "e88b466d-2398-4cfb-9db4-233f228d1869"
   },
   "source": [
    "### Entrainement du modèle d'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4de15f7-28ca-451f-a627-16885621799b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53545,
     "status": "ok",
     "timestamp": 1727939836433,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "f4de15f7-28ca-451f-a627-16885621799b",
    "outputId": "334ef426-1ff8-4651-9323-92b13212b559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4991 - loss: 3477824.5000 - val_accuracy: 0.5010 - val_loss: 5.3479\n",
      "Epoch 2/5\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5260 - loss: 2197666.0000 - val_accuracy: 0.4983 - val_loss: 5.3420\n",
      "Epoch 3/5\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5057 - loss: 1978229.3750 - val_accuracy: 0.4983 - val_loss: 5.3373\n",
      "Epoch 4/5\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5408 - loss: 1390200.3750 - val_accuracy: 0.4983 - val_loss: 5.3335\n",
      "Epoch 5/5\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5213 - loss: 1143951.2500 - val_accuracy: 0.4983 - val_loss: 5.3301\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df['target'].values\n",
    "y_test = test_df['target'].values\n",
    "\n",
    "# Entraînement du modèle avec validation et sauvegarde de l'historique\n",
    "history = model.fit(\n",
    "    train_padded,         # Données d'entraînement\n",
    "    y_train,              # Étiquettes d'entraînement\n",
    "    epochs=5,            # Nombre d'époques\n",
    "    batch_size=32,        # Taille des batchs\n",
    "    validation_data=(test_padded, y_test),  # Validation sur les données de test\n",
    "    verbose=1             # Afficher l'évolution pendant l'entraînement\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d690b26-20e7-414c-9e34-cf3cf1060781",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 51004,
     "status": "error",
     "timestamp": 1727939909145,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "3d690b26-20e7-414c-9e34-cf3cf1060781",
    "outputId": "82020231-c7ef-4f87-d54f-d07c2a5354f0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Récupération de l'historique des erreurs et de l'accuracy\n",
    "train_loss = history.history['loss']            # Erreur sur l'ensemble d'entraînement\n",
    "val_loss = history.history['val_loss']          # Erreur sur l'ensemble de validation\n",
    "train_acc = history.history['accuracy']         # Accuracy sur l'ensemble d'entraînement\n",
    "val_acc = history.history['val_accuracy']       # Accuracy sur l'ensemble de validation\n",
    "\n",
    "# Nombre d'époques\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Tracer l'évolution de la loss (erreur)\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Courbe de la loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Evolution de la fonction d\\'erreur')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Courbe de l'accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Evolution de l\\'accuracy')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8561e5-4492-4034-aa75-3553115ba15e",
   "metadata": {
    "id": "fb8561e5-4492-4034-aa75-3553115ba15e"
   },
   "source": [
    "# Modèle basé sur Bert (pré-entrainé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17f4895f-4a7c-40e7-a992-9b216c5c45af",
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1727941353500,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "17f4895f-4a7c-40e7-a992-9b216c5c45af"
   },
   "outputs": [],
   "source": [
    "# pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "849ad0fd-b35a-482c-bd12-a74f42807e69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1727941354883,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "849ad0fd-b35a-482c-bd12-a74f42807e69",
    "outputId": "5af29c22-4c42-4e1a-9d85-36444632c009"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model from Hugging Face\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to preprocess the text and make predictions\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Forward pass, get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted sentiment label\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    # Map the prediction to the sentiment\n",
    "    sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "    return sentiment_labels[predicted_class]\n",
    "\n",
    "# Example usage\n",
    "text = \"I love using the new RoBERTa model for sentiment analysis!\"\n",
    "sentiment = predict_sentiment(text)\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17197e-b430-47cb-9147-561a1ac6f9bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 1851,
     "status": "error",
     "timestamp": 1727941356731,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "5e17197e-b430-47cb-9147-561a1ac6f9bd",
    "outputId": "1f4a4e19-12d6-4164-ea68-0b6112cd8042"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the tokenizer and model from Hugging Face\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment_roberta(texts):\n",
    "    # Tokenize the input texts\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Forward pass, get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted class\n",
    "    logits = outputs.logits\n",
    "    predicted_classes = torch.argmax(logits, dim=1)\n",
    "\n",
    "    return predicted_classes\n",
    "\n",
    "# Mapping the RoBERTa outputs to your target classes (0 = positive, 1 = negative)\n",
    "def map_roberta_to_custom_labels(roberta_prediction):\n",
    "    # RoBERTa has 3 classes: [negative, neutral, positive]\n",
    "    # We'll map neutral and negative to 'negative' (1), positive to 'positive' (0)\n",
    "    return 1 if roberta_prediction in [0, 1] else 0\n",
    "\n",
    "# Process the DataFrame and predict sentiments for train/test data\n",
    "def process_and_predict(df):\n",
    "    predicted_labels = []\n",
    "\n",
    "    for text in df['text']:\n",
    "        # Predict sentiment for each tweet\n",
    "        roberta_prediction = predict_sentiment_roberta([text])[0].item()\n",
    "\n",
    "        # Map RoBERTa sentiment to custom labels\n",
    "        custom_label = map_roberta_to_custom_labels(roberta_prediction)\n",
    "        predicted_labels.append(custom_label)\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "# Predict on training set\n",
    "train_predictions = process_and_predict(train_df)\n",
    "train_labels = train_df['target'].tolist()\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = process_and_predict(test_df)\n",
    "test_labels = test_df['target'].tolist()\n",
    "\n",
    "# Evaluate the results\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "print(\"Train Accuracy: \", train_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# Classification report for further insights\n",
    "print(\"\\nClassification Report on Train Data:\")\n",
    "print(classification_report(train_labels, train_predictions, target_names=[\"positive\", \"negative\"]))\n",
    "\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "print(classification_report(test_labels, test_predictions, target_names=[\"positive\", \"negative\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a05081-deb9-44de-8fb7-8d4cf9772118",
   "metadata": {
    "id": "96a05081-deb9-44de-8fb7-8d4cf9772118"
   },
   "source": [
    "# Test Roberta tweets sentiment analysis avec fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57eb3017-eeaa-41a0-89d4-93ab1df63eb5",
   "metadata": {
    "id": "57eb3017-eeaa-41a0-89d4-93ab1df63eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n",
      "Nom du GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Version de PyTorch: 2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())  # Devrait retourner True\n",
    "print(\"Nom du GPU:\", torch.cuda.get_device_name(0))   # Affiche le nom du GPU\n",
    "print(\"Version de PyTorch:\", torch.__version__)       # Devrait afficher 2.4.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "874bf319-c1e6-4afd-802f-a7b9dda5c1dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1727941201609,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "874bf319-c1e6-4afd-802f-a7b9dda5c1dc",
    "outputId": "fc51a035-c331-41b2-b86c-9b457a705f46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\AIEP7\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f0a89e5-1553-4c49-87d5-eeec802b06ee",
   "metadata": {
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1727941203493,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "7cff257f-314f-4e63-9f9e-8e71d8f4b335"
   },
   "outputs": [],
   "source": [
    "# Freeze all layers except the last classification layer\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "547f1784-0434-48ea-a60a-0ef5aedefdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Custom Dataset class to handle tokenization\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        target = self.targets[index]\n",
    "\n",
    "        # Tokenization\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df1df57e-817b-48e0-9a3d-aef872edb2aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1727941211500,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "df1df57e-817b-48e0-9a3d-aef872edb2aa",
    "outputId": "29e317aa-d0ea-4719-9230-7bbff7da3377"
   },
   "outputs": [],
   "source": [
    "# # Sous-échantillonage de train_df\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Taille de l'échantillon (20% du total)\n",
    "# sample_size = 0.2\n",
    "\n",
    "# # Création du sous-échantillon avec stratification sur la colonne 'target'\n",
    "# train_sample, _ = train_test_split(train_df,\n",
    "#                                    test_size=1 - sample_size,\n",
    "#                                    stratify=train_df['target'],\n",
    "#                                    random_state=42)\n",
    "\n",
    "# # Affichage de la répartition des classes dans le sous-échantillon\n",
    "# print(train_sample['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f09e563-e4d0-46ea-bac0-4dd5301c7390",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1727940520350,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "7f09e563-e4d0-46ea-bac0-4dd5301c7390",
    "outputId": "2330e821-da7f-4077-8810-f7e9d6c382bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recap modèle et assignation de device pour le calcul\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9546af3b-939f-44b0-817e-2e2cce4d905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet_dataset import TweetDataset  # Importer la classe depuis le module séparé\n",
    "\n",
    "# Function to create the DataLoader\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    dataset = TweetDataset(\n",
    "        texts=df['text'].to_numpy(),\n",
    "        targets=df['target'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    \n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4  # Adjust according to your machine\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cd2ef6a-0aa4-4741-8b5f-4ac4c6b7e153",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1727941060216,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "c75fd7e5-e0d0-4df9-98cb-fb293d9e48d4",
    "outputId": "f90289a1-48de-403a-fff6-4595f0404cbb"
   },
   "outputs": [],
   "source": [
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    maxlen = 40  # Max tokens\n",
    "    batch_size = 16  # Increase to lower calculation time\n",
    "\n",
    "    # Prepare the data\n",
    "    train_dataloader = create_data_loader(train_df, tokenizer, maxlen, batch_size)\n",
    "    test_dataloader = create_data_loader(test_df, tokenizer, maxlen, batch_size)\n",
    "    # Example usage of DataLoader (test de l'utilisation de la classe tweet_dataset\n",
    "    # for batch in train_dataloader:\n",
    "    #     print(batch)\n",
    "    #     break  # Remove this line to process the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73946f63-f247-4dad-aab2-a13556d1a842",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1727941060216,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "c75fd7e5-e0d0-4df9-98cb-fb293d9e48d4",
    "outputId": "f90289a1-48de-403a-fff6-4595f0404cbb"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "# Optimizer and learning rate (adjustable)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de491fb7-41eb-4050-a1db-59b19a2928b4",
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1727941232104,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "de491fb7-41eb-4050-a1db-59b19a2928b4"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    model = model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=targets\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        total_correct += torch.sum(preds == targets)\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_correct.double() / total_samples, total_loss / total_samples\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, dataloader, device):\n",
    "    model = model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            total_correct += torch.sum(preds == targets)\n",
    "            total_samples += targets.size(0)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    accuracy = total_correct.double() / total_samples\n",
    "    return accuracy, predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0ff838d-90d0-4053-a489-42499b039641",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263605,
     "status": "ok",
     "timestamp": 1727940801597,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "c0ff838d-90d0-4053-a489-42499b039641",
    "outputId": "e82597bd-fabd-4232-e190-9358fe7ab837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.0366 | Train Accuracy: 0.7359\n",
      "Epoch 2/20 | Train Loss: 0.0293 | Train Accuracy: 0.7769\n",
      "Epoch 3/20 | Train Loss: 0.0291 | Train Accuracy: 0.7798\n",
      "Epoch 4/20 | Train Loss: 0.0287 | Train Accuracy: 0.7860\n",
      "Epoch 5/20 | Train Loss: 0.0284 | Train Accuracy: 0.7913\n",
      "Epoch 6/20 | Train Loss: 0.0280 | Train Accuracy: 0.7928\n",
      "Epoch 7/20 | Train Loss: 0.0282 | Train Accuracy: 0.7872\n",
      "Epoch 8/20 | Train Loss: 0.0279 | Train Accuracy: 0.7919\n",
      "Epoch 9/20 | Train Loss: 0.0277 | Train Accuracy: 0.7892\n",
      "Epoch 10/20 | Train Loss: 0.0277 | Train Accuracy: 0.7898\n",
      "Epoch 11/20 | Train Loss: 0.0275 | Train Accuracy: 0.7951\n",
      "Epoch 12/20 | Train Loss: 0.0275 | Train Accuracy: 0.7939\n",
      "Epoch 13/20 | Train Loss: 0.0275 | Train Accuracy: 0.7925\n",
      "Epoch 14/20 | Train Loss: 0.0271 | Train Accuracy: 0.7969\n",
      "Epoch 15/20 | Train Loss: 0.0271 | Train Accuracy: 0.7922\n",
      "Epoch 16/20 | Train Loss: 0.0273 | Train Accuracy: 0.7995\n",
      "Epoch 17/20 | Train Loss: 0.0272 | Train Accuracy: 0.7910\n",
      "Epoch 18/20 | Train Loss: 0.0269 | Train Accuracy: 0.8022\n",
      "Epoch 19/20 | Train Loss: 0.0266 | Train Accuracy: 0.8042\n",
      "Epoch 20/20 | Train Loss: 0.0270 | Train Accuracy: 0.7978\n"
     ]
    }
   ],
   "source": [
    "epochs = 20  # Adjust as necessary\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc, train_loss = train_epoch(model, train_dataloader, optimizer, device)\n",
    "    print(f'Epoch {epoch + 1}/{epochs} | Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "601fdbcf-aec8-4259-b372-9f852d402ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import recall_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to calculate recall (as a callback metric)\n",
    "# def calculate_recall(y_true, y_pred):\n",
    "#     y_pred = torch.argmax(y_pred, dim=1).cpu().numpy()\n",
    "#     y_true = y_true.cpu().numpy()\n",
    "#     return recall_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24ea7e29-35df-4fcb-a73e-18aecf10b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and evaluation function\n",
    "# def train_epoch(model, dataloader, optimizer, device):\n",
    "#     model.train()\n",
    "#     losses = []\n",
    "#     correct_predictions = 0\n",
    "#     total_predictions = 0\n",
    "\n",
    "#     for batch in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         inputs = batch['input_ids'].to(device)\n",
    "#         masks = batch['attention_mask'].to(device)\n",
    "#         targets = batch['targets'].to(device)\n",
    "\n",
    "#         outputs = model(input_ids=inputs, attention_mask=masks).logits\n",
    "#         loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "        \n",
    "#         _, preds = torch.max(outputs, dim=1)\n",
    "#         correct_predictions += torch.sum(preds == targets)\n",
    "#         total_predictions += targets.size(0)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         losses.append(loss.item())\n",
    "\n",
    "#     return correct_predictions.double() / total_predictions, np.mean(losses)\n",
    "\n",
    "# def eval_model(model, dataloader, device):\n",
    "#     model.eval()\n",
    "#     losses = []\n",
    "#     correct_predictions = 0\n",
    "#     total_predictions = 0\n",
    "#     recalls = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in dataloader:\n",
    "#             inputs = batch['input_ids'].to(device)\n",
    "#             masks = batch['attention_mask'].to(device)\n",
    "#             targets = batch['targets'].to(device)\n",
    "\n",
    "#             outputs = model(input_ids=inputs, attention_mask=masks).logits\n",
    "#             loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "#             _, preds = torch.max(outputs, dim=1)\n",
    "#             correct_predictions += torch.sum(preds == targets)\n",
    "#             total_predictions += targets.size(0)\n",
    "            \n",
    "#             # Recall calculation\n",
    "#             recalls.append(calculate_recall(targets, outputs))\n",
    "\n",
    "#             losses.append(loss.item())\n",
    "\n",
    "#     return correct_predictions.double() / total_predictions, np.mean(losses), np.mean(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed865123-04cc-4084-981e-2600dc3aba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training loop with callbacks, early stopping and history tracking\n",
    "# def train_model(model, train_dataloader, test_dataloader, optimizer, epochs, device, patience=3):\n",
    "#     history = {\n",
    "#         'train_loss': [],\n",
    "#         'test_loss': [],\n",
    "#         'train_recall': [],\n",
    "#         'test_recall': []\n",
    "#     }\n",
    "\n",
    "#     best_recall = 0\n",
    "#     early_stopping_counter = 0\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         # Training\n",
    "#         train_acc, train_loss = train_epoch(model, train_dataloader, optimizer, device)\n",
    "#         # Evaluation\n",
    "#         test_acc, test_loss, test_recall = eval_model(model, test_dataloader, device)\n",
    "        \n",
    "#         # Save metrics to history\n",
    "#         history['train_loss'].append(train_loss)\n",
    "#         history['test_loss'].append(test_loss)\n",
    "#         history['train_recall'].append(train_acc)\n",
    "#         history['test_recall'].append(test_recall)\n",
    "\n",
    "#         # Print progress\n",
    "#         print(f'Epoch {epoch + 1}/{epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Recall: {test_recall:.4f}')\n",
    "\n",
    "#         # Early stopping based on loss improvement\n",
    "#         if test_recall > best_recall:\n",
    "#             best_recall = test_recall\n",
    "#             early_stopping_counter = 0\n",
    "#             # Optionally save the best model here\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "#         else:\n",
    "#             early_stopping_counter += 1\n",
    "\n",
    "#         if early_stopping_counter >= patience:\n",
    "#             print(f\"Early stopping after {epoch + 1} epochs\")\n",
    "#             break\n",
    "\n",
    "#     # Save history to a file\n",
    "#     with open('history.npy', 'wb') as f:\n",
    "#         np.save(f, history)\n",
    "\n",
    "#     # Plot loss and recall\n",
    "#     plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32cad370-e422-45ce-82ab-ccf20b8bc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(history):\n",
    "#     epochs = len(history['train_loss'])\n",
    "#     plt.figure(figsize=(14, 5))\n",
    "\n",
    "#     # Plot loss\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(range(epochs), history['train_loss'], label='Train Loss')\n",
    "#     plt.plot(range(epochs), history['test_loss'], label='Test Loss')\n",
    "#     plt.legend()\n",
    "#     plt.title('Loss Evolution')\n",
    "    \n",
    "#     # Plot recall\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(range(epochs), history['train_recall'], label='Train Recall')\n",
    "#     plt.plot(range(epochs), history['test_recall'], label='Test Recall')\n",
    "#     plt.legend()\n",
    "#     plt.title('Recall Evolution')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cf880ab-6fd8-4d93-9b4e-c073d52c6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, train_dataloader, test_dataloader, optimizer, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce9bd771-bff8-46b0-aa6b-90d399c37f37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10462,
     "status": "ok",
     "timestamp": 1727940827256,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "ce9bd771-bff8-46b0-aa6b-90d399c37f37",
    "outputId": "207cd658-6221-4c01-c7de-745c827809ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7735\n",
      "\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.74      0.83      0.79       726\n",
      "    negative       0.81      0.72      0.76       731\n",
      "\n",
      "    accuracy                           0.77      1457\n",
      "   macro avg       0.78      0.77      0.77      1457\n",
      "weighted avg       0.78      0.77      0.77      1457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_acc, test_preds, test_true = eval_model(model, test_dataloader, device)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "print(classification_report(test_true, test_preds, target_names=[\"positive\", \"negative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50987908-831d-4c36-853c-24265d579e86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2207,
     "status": "ok",
     "timestamp": 1727940858009,
     "user": {
      "displayName": "Mayer Cécile",
      "userId": "03016020088537475993"
     },
     "user_tz": -120
    },
    "id": "50987908-831d-4c36-853c-24265d579e86",
    "outputId": "66ace61f-12b0-4b78-da06-df8cc14b8d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./models/roberta_fine_tuned_10_03_2024_10_58\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%m_%d_%Y_%H_%M\")\n",
    "\n",
    "# Save the model\n",
    "model_save_path = f'./models/roberta_fine_tuned_{dt_string}'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5368a41b-9e43-45e3-a27d-bc076528da72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1DddhZbYzSVf3snWVyVayyvdyLThtmhYo",
     "timestamp": 1727941407198
    }
   ]
  },
  "kernelspec": {
   "display_name": "AIEP7",
   "language": "python",
   "name": "aiep7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
